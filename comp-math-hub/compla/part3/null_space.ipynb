{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Null Space and Rank\n",
                "\n",
                "We will now study another important vector space associated with a $m \\times n$ matrix $A$: its **null space**, denoted $N(A)$. The null space of $A$ is the set of all solutions to $A \\mathbf x = \\mathbf 0$. As with the column and row spaces, we can also define the null space of $A^\\top$, also called the **left null space** $N(A^\\top)$.\n",
                "\n",
                "At first glance this definition is not very straightforward. We cannot even directly express $N(A)$ as the span of a set of vectors (yet). However, it is easy to see that the solution set to $A \\mathbf x = \\mathbf 0$ is a vector space. Take any two solutions $\\mathbf x_1$ and $\\mathbf x_2$. Then an arbitrary linear combination of them is also a solution, since\n",
                "\n",
                "$$ A (c_1 \\mathbf x_1 + c_2 \\mathbf x_2) = c_1 A \\mathbf x_1 + c_2 A \\mathbf x_2 = \\mathbf 0. $$\n",
                "\n",
                "Finally, note that $N(A)$ is a subspace of $\\mathbb R^n$, since all solutions $\\mathbf x$ are $n$-vectors. Correspondingly, $N(A^\\top)$ is a subspace of $\\mathbb R^m$."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Solving $A \\mathbf x = \\mathbf 0$\n",
                "\n",
                "To find $N(A)$, we must solve $A \\mathbf x = \\mathbf 0$. We already know how to transform $A$ into RREF by Gauss-Jordan elimination. If the result has no free variables (each column contains a pivot), then there is just a single solution: $\\mathbf x = \\mathbf 0$. $N(A)$ is thus trivial---the zero vector space.\n",
                "\n",
                "If there are free variables, then $N(A)$ is not trivial. We can express it as the span of several representative vectors from this space. While there are infinitely many ways to do so, we will describe one that is systematic and correct.\n",
                "\n",
                "Suppose $A$ is in RREF. Then for each free variable, set it equal to 1 and all other free variables to 0. Solve for the value of the pivot variables by inspection or back substitution. This gives us a \"special\" solution to $A \\mathbf x = \\mathbf 0$. Repeat this process with each of the other free variables and obtain a \"special\" solution for each. $N(A)$ is then the span of all special solutions obtained.\n",
                "\n",
                "The reason that this works is that each special solution is *independent*; none of them can be formed as linear combinations of the others. By going through this process for each free variable, we also make sure that we have captured all possible solutions to $A \\mathbf x = \\mathbf 0$ and thus all of $N(A)$."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example\n",
                "\n",
                "Consider the following matrix in RREF:\n",
                "\n",
                "$$ R = \\begin{bmatrix} 1 \u0026 0 \u0026 a \u0026 0 \u0026 c \\\\ 0 \u0026 1 \u0026 b \u0026 0 \u0026 d \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \u0026 e \\\\ 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \\end{bmatrix} $$\n",
                "\n",
                "The free variables are $x_3$ and $x_5$. We first set $x_3=1$ and $x_5=0$; this gives us the rest of the first special solution $x_1=-a$, $x_2=-b$, $x_4=0$. Next, we set $x_3=0$ and $x_5=1$; this gives us the rest of the second special solution $x_1=-c$, $x_2=-d$, $x_4=-e$. We thus obtain\n",
                "\n",
                "$$ N(R) = \\{\\mathbf x \\,|\\, R \\mathbf x = \\mathbf 0\\} = \\text{Span}\\{(-a,-b,1,0,0), (-c,-d,0,-e,1)\\}. $$\n",
                "\n",
                "Again, $N(R)$ is a subspace of $\\mathbb R^n$, or in this example $\\mathbb R^5$. If $R$ is the RREF of some other matrix $A$, then it follows that $N(A) = N(R)$, since they should have the same set of solutions. One last takeaway is that if the matrix is wide with $n\u003em$, we are guaranteed to have free variables, the null space is guaranteed to be nontrivial, and there are infinitely many solutions to $A \\mathbf x = \\mathbf 0$."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Solving $A \\mathbf x = \\mathbf b$\n",
                "\n",
                "Having fully solved $A \\mathbf x = \\mathbf 0$, we can now turn our attention to $A \\mathbf x = \\mathbf b$, where $\\mathbf b$ is not zero. We are already familiar with the cases of one or no solution; here we will describe the case of multiple solutions. As with $A \\mathbf x = \\mathbf 0$, there are infinitely many ways to do so, but we will write the solutions by relating them to $N(A)$. \n",
                "\n",
                "Suppose we have some *particular solution* $\\mathbf x_p$ that solves $A \\mathbf x = \\mathbf b$. Then if we add to it any vector $\\mathbf x_n$ from $N(A)$, the result still solves $A \\mathbf x = \\mathbf b$, because\n",
                "\n",
                "$$ A(\\mathbf x_p + \\mathbf x_n) = A \\mathbf x_p + A \\mathbf x_n = \\mathbf b + \\mathbf 0 = \\mathbf b. $$\n",
                "\n",
                "All that remains is to find a particular solution $\\mathbf x_p$ that is not in $N(A)$. Suppose we have formed the augmented matrix for our linear system and reduced it to RREF. Then $\\mathbf x_p$ can be found by setting *all* free variables to $0$ and then solving for the pivot variables.\n",
                "\n",
                "Consider the following example:\n",
                "\n",
                "$$ \\begin{bmatrix} R \u0026 | \u0026 \\mathbf d \\end{bmatrix} = \\begin{bmatrix} 1 \u0026 0 \u0026 a \u0026 0 \u0026 c \u0026 | \u0026 f \\\\ 0 \u0026 1 \u0026 b \u0026 0 \u0026 d \u0026 | \u0026 g \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \u0026 e \u0026 | \u0026 h \\\\ 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 | \u0026 0 \\end{bmatrix} $$\n",
                "\n",
                "First note that the last component of $\\mathbf d$ must be $0$; otherwise, the system would be inconsistent and there would be no solution. We set the free variables $x_3$ and $x_5$ to $0$ and solve for the remaining variables: $x_1=f$, $x_2=g$, $x_4=h$. We thus have $\\mathbf x_p = (f,g,0,h,0)$.\n",
                "\n",
                "The complete set of solutions to $R \\mathbf x = \\mathbf d$, as well as $A \\mathbf x = \\mathbf b$ assuming that was the original system, is thus\n",
                "\n",
                "$$ \\mathbf x = \\mathbf x_p + \\mathbf x_n = (f,g,0,h,0) + \\mathbf x_n, \\quad \\mathbf x_n \\in \\text{Span}\\{(-a,-b,1,0,0), (-c,-d,0,-e,1)\\}. $$\n",
                "\n",
                "A slightly less cumbersome way of writing this is as follows:\n",
                "\n",
                "$$ \\mathbf x = (f,g,0,h,0) + x_3 (-a,-b,1,0,0) + x_5 (-c,-d,0,-e,1), \\quad x_3, x_5 \\in \\mathbb R $$\n",
                "\n",
                "Note that this solution set is **not** a vector space. Instead, this idea of \"constant vector plus vectors from a vector space\" forms what is called an **affine space**. You can still visualize this as a hyperplane in $n$-dimensional space, but shifted away from the origin."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Rank\n",
                "\n",
                "The **rank** of a matrix can be defined by the number of pivots in its REF. This number is the true \"size\" of the linear system, or the number of independent linear equations. If we look at the rows of a REF matrix, the zero rows do not count toward the rank, as they are linear combinations of the rows with pivots. If we look at the columns, the free columns do not count toward the rank, as they are linear combinations of the pivot columns.\n",
                "\n",
                "Consider the extreme case of a matrix with one column or one row. Both of these matrices have rank equal to 1. In the former case, every \"row\" is a multiple of the first \"row\"; in the latter case, every \"column\" is a multiple of the first \"column\". The same analysis also holds for the matrix result of an outer product of two vectors $\\mathbf u \\mathbf v^\\top$.\n",
                "\n",
                "## Rank and Matrix Size\n",
                "\n",
                "Let $r$ be the rank of a $m \\times n$ matrix $A$. Clearly, $r \\leq \\min(m,n)$; we cannot have more pivots than the smaller of either of $A$'s dimensions. Then we can have one of four cases:\n",
                "\n",
                "* $r \u003c \\min(m,n)$. We say that $A$ is \"not full rank\". There is at least one zero row and one free column. $A \\mathbf x = \\mathbf b$ may have either no or infinitely many solutions.\n",
                "* $r = m \u003c n$. We say that $A$ is \"full row rank\"; this can only occur if $A$ is square or wide ($m \\leq n$). $N(A)$ is nontrivial since there is at least one free column, and $A \\mathbf x = \\mathbf b$ is guaranteed to have infinitely many solutions.\n",
                "* $r = n \u003c m$. We say that $A$ is \"full column rank\"; this can only occur if $A$ is square or tall ($m \\geq n$). $N(A)$ is trivial since there are no free columns, and $A \\mathbf x = \\mathbf b$ has either no or one solution.\n",
                "* $r = m = n$. $A$ is both full row rank and full column rank (alternatively, it is just \"full rank\"). $N(A)$ is trivial since there are no free columns. $A$ is guaranteed to be invertible, and $A \\mathbf x = \\mathbf b$ has exactly one solution. \n",
                "\n",
                "It is fairly easy to compute the rank of a matrix using NumPy. There is a procedure for computing the inverse as well, if it exists. Fortunately, there is no need to use elimination."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "rank(A) = 2 \u003c min(3,4); not full rank\nrank(B) = 2 = m; full row rank\nrank(C) = 2 = n; full column rank\nrank(D) = 3 = m = n; full rank and invertible\nThe inverse of D is\n [[-4.5  7.  -1.5]\n [-2.   4.  -1. ]\n [ 1.5 -2.   0.5]]\n"
                }
            ],
            "source": [
                "import numpy as np\n",
                "\n",
                "A = np.array([[1,3,0,2],\n",
                "              [0,0,1,4],\n",
                "              [1,3,1,6]])\n",
                "print(\"rank(A) =\", np.linalg.matrix_rank(A), \"\u003c min(3,4); not full rank\")\n",
                "\n",
                "B = np.array([[1,1,1],\n",
                "              [1,2,-1]])\n",
                "print(\"rank(B) =\", np.linalg.matrix_rank(B), \"= m; full row rank\")\n",
                "\n",
                "C = np.array([[1,1],\n",
                "              [1,2],\n",
                "              [-2,-3]])\n",
                "print(\"rank(C) =\", np.linalg.matrix_rank(C), \"= n; full column rank\")\n",
                "\n",
                "D = np.array([[0,1,2],\n",
                "              [1,0,3],\n",
                "              [4,-3,8]])\n",
                "print(\"rank(D) =\", np.linalg.matrix_rank(D), \"= m = n; full rank and invertible\")\n",
                "\n",
                "print(\"The inverse of D is\\n\", np.linalg.inv(D))"
            ]
        }
    ]
}
